{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]], shape=(450, 450, 3), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[[  9   0   0]\n",
      "  [ 10   1   0]\n",
      "  [ 13   4   0]\n",
      "  ...\n",
      "  [  4   5   0]\n",
      "  [  5   5   0]\n",
      "  [  5   5   0]]\n",
      "\n",
      " [[  9   0   0]\n",
      "  [ 10   1   0]\n",
      "  [ 14   5   0]\n",
      "  ...\n",
      "  [  4   5   0]\n",
      "  [  4   4   0]\n",
      "  [  4   4   0]]\n",
      "\n",
      " [[ 12   3   0]\n",
      "  [ 13   5   0]\n",
      "  [ 17   9   0]\n",
      "  ...\n",
      "  [  5   6   0]\n",
      "  [  5   5   0]\n",
      "  [  5   5   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[190 157 114]\n",
      "  [191 158 115]\n",
      "  [186 154 113]\n",
      "  ...\n",
      "  [ 53  35  13]\n",
      "  [ 55  37  13]\n",
      "  [ 55  38  12]]\n",
      "\n",
      " [[194 163 117]\n",
      "  [193 165 118]\n",
      "  [188 161 118]\n",
      "  ...\n",
      "  [ 52  36  13]\n",
      "  [ 53  37  12]\n",
      "  [ 53  37  12]]\n",
      "\n",
      " [[192 164 116]\n",
      "  [192 165 118]\n",
      "  [188 161 116]\n",
      "  ...\n",
      "  [ 52  36  13]\n",
      "  [ 53  37  12]\n",
      "  [ 53  37  12]]], shape=(450, 450, 3), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[[255 242 207]\n",
      "  [255 241 206]\n",
      "  [255 241 206]\n",
      "  ...\n",
      "  [164 124  75]\n",
      "  [163 122  76]\n",
      "  [163 122  76]]\n",
      "\n",
      " [[255 242 207]\n",
      "  [255 241 206]\n",
      "  [255 241 206]\n",
      "  ...\n",
      "  [165 125  76]\n",
      "  [164 123  77]\n",
      "  [164 123  77]]\n",
      "\n",
      " [[255 242 207]\n",
      "  [255 241 206]\n",
      "  [255 241 206]\n",
      "  ...\n",
      "  [165 125  76]\n",
      "  [164 123  77]\n",
      "  [164 123  77]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[232 179 109]\n",
      "  [231 179 106]\n",
      "  [230 177 107]\n",
      "  ...\n",
      "  [217 130  63]\n",
      "  [219 132  65]\n",
      "  [219 132  65]]\n",
      "\n",
      " [[228 171 100]\n",
      "  [228 172  98]\n",
      "  [228 171 100]\n",
      "  ...\n",
      "  [217 128  62]\n",
      "  [218 131  64]\n",
      "  [218 131  64]]\n",
      "\n",
      " [[229 171  98]\n",
      "  [229 171  98]\n",
      "  [229 171  98]\n",
      "  ...\n",
      "  [217 128  62]\n",
      "  [218 131  64]\n",
      "  [218 131  64]]], shape=(450, 450, 3), dtype=uint8)\n",
      "tf.Tensor(\n",
      "[[[172 172 172]\n",
      "  [174 174 174]\n",
      "  [180 180 180]\n",
      "  ...\n",
      "  [194 194 194]\n",
      "  [193 193 193]\n",
      "  [193 193 193]]\n",
      "\n",
      " [[169 169 169]\n",
      "  [169 169 169]\n",
      "  [172 172 172]\n",
      "  ...\n",
      "  [189 189 189]\n",
      "  [190 190 190]\n",
      "  [190 190 190]]\n",
      "\n",
      " [[154 154 154]\n",
      "  [154 154 154]\n",
      "  [155 155 155]\n",
      "  ...\n",
      "  [179 179 179]\n",
      "  [179 179 179]\n",
      "  [179 179 179]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[158 158 158]\n",
      "  [161 161 161]\n",
      "  [165 165 165]\n",
      "  ...\n",
      "  [ 68  68  68]\n",
      "  [ 72  72  72]\n",
      "  [ 72  72  72]]\n",
      "\n",
      " [[148 148 148]\n",
      "  [152 152 152]\n",
      "  [163 163 163]\n",
      "  ...\n",
      "  [ 71  71  71]\n",
      "  [ 75  75  75]\n",
      "  [ 75  75  75]]\n",
      "\n",
      " [[148 148 148]\n",
      "  [152 152 152]\n",
      "  [163 163 163]\n",
      "  ...\n",
      "  [ 71  71  71]\n",
      "  [ 75  75  75]\n",
      "  [ 75  75  75]]], shape=(450, 450, 3), dtype=uint8)\n",
      "2000\n",
      "(68, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the AFLW2K dataset\n",
    "ds = tfds.load('aflw2k3d', split='train')\n",
    "\n",
    "for ex in ds.take(4):\n",
    "    print(ex['image'])\n",
    "\n",
    "# Here we will split the image data and its corresponding 2D landmark coordinates.\n",
    "images = []\n",
    "landmarks2D = []\n",
    "\n",
    "for ex in ds.take(2000):\n",
    "    # extracts the image data from the current ex\n",
    "    images.append(ex['image'])\n",
    "    # extracts the 2D landmark coordinates\n",
    "    landmarks2D.append(ex['landmarks_68_3d_xy_normalized'])\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "images = np.array(images)\n",
    "landmarks2D = np.array(landmarks2D)\n",
    "\n",
    "# print the length of the image array \n",
    "print (len(images))\n",
    "# print the shape of the 2D landmark coordinates\n",
    "print (landmarks2D[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 \n",
      " 500\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "\n",
    "# Shuffle indices\n",
    "num_examples = len(images)\n",
    "# create an array of integers ranging from 0 to num_examples to represent the indices of the data set\n",
    "indices = np.arange(num_examples)\n",
    "# shuffle these indices \n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Define split sizes\n",
    "train_size = 1500\n",
    "# 2000-1500=500\n",
    "test_size = num_examples - train_size \n",
    "\n",
    "print(train_size, \"\\n\", test_size)\n",
    "\n",
    "# Split indices: some for train data (1500) and some for test data(500)\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "# Split the dataset\n",
    "train_images, test_images = images[train_indices], images[test_indices]\n",
    "\n",
    "train_landmarks, test_landmarks = landmarks2D[train_indices], landmarks2D[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Heba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "# Define the model outside of a tf.function decorated function\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(450, 450, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(136, activation='relu'),  # Output layer for 68 landmarks (68 * 2 = 136)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# Mean Squared Error = mse the loss function\n",
    "# Mean Absolute Error = mae measures the average absolute difference between the predicted and actual values.\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3s/step - loss: 300.0565 - mae: 2.9078 - val_loss: 0.3210 - val_mae: 0.5528\n",
      "Epoch 2/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 3s/step - loss: 0.3211 - mae: 0.5530 - val_loss: 0.3210 - val_mae: 0.5528\n",
      "Epoch 3/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3s/step - loss: 0.3206 - mae: 0.5527 - val_loss: 0.3210 - val_mae: 0.5528\n",
      "Epoch 4/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 3s/step - loss: 0.3212 - mae: 0.5530 - val_loss: 0.3210 - val_mae: 0.5528\n",
      "Epoch 5/10\n",
      "\u001b[1m35/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m19s\u001b[0m 2s/step - loss: 0.3212 - mae: 0.5530"
     ]
    }
   ],
   "source": [
    "# Reshape the target values to match the output shape of the model\n",
    "train_landmarks_reshaped = train_landmarks.reshape(train_landmarks.shape[0], -1)\n",
    "\n",
    "# train the model \n",
    "history = model.fit(train_images, train_landmarks_reshaped, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number of landmarks\n",
    "num_landmarks = model.output_shape[1] // 2  # Divide by 2 because each landmark has x and y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lowest training loss from the history\n",
    "lowest_loss = min(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 620ms/step - loss: 0.3214 - mae: 0.5531\n"
     ]
    }
   ],
   "source": [
    "# Reshape test_landmarks to match the output shape of the model\n",
    "test_landmarks_reshaped = test_landmarks.reshape(test_landmarks.shape[0], -1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(test_images, test_landmarks_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3214515447616577\n",
      "Test MAE: 0.5532915592193604\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of landmarks: 68\n",
      "Lowest training loss: 0.32063522934913635\n"
     ]
    }
   ],
   "source": [
    "# Print the number of landmarks and lowest loss\n",
    "print(\"Number of landmarks:\", num_landmarks)\n",
    "print(\"Lowest training loss:\", lowest_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
